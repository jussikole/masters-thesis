Model based sequence classification method assume the time series is generated by some statistical model and use the underlying model for predicting the future shape of the time series. Before using the model, a training set is needed for learning the model's parameters. Then, the trained model gives us the shape of the future time series.

\subsection{Model Parameter Estimation}
Let's assume we know the form of the underlying model. Then, we can denote the probability distribution of the class $w_i$ by $p(\mathbf{x}|w_i; \mathbf{\theta}_i)$, where $\mathbf{\theta}_i$ is a vector containing the unknown distribution parameters. Let's also assume that that the observations $x_k$ we made are independent both between the classes and inside the classes. One way to find $\theta_i$ is to maximize the likelihood function
\begin{equation}
\mathbf{\hat{\Theta}}_{ML} = \underset{\mathbf{\Theta}}{\operatorname{argmax}}{\prod_{k=1}^N p(\mathbf{x}_k; \mathbf{\Theta})},
\end{equation} 

which can then be solved for $\mathbf{\hat{\Theta}}_{ML}$ by setting the first derivative equal to zero. In many cases it is convenient to use logarithmic likelihood function as the product turns into a sum while the logarithmic function preserves the location of the maxima.

We can extend this idea by using the Bayes Rule
\begin{equation}
p(\mathbf{\Theta}|\mathbf{X}) = \frac{p(\mathbf{\Theta}) p(\mathbf{X}|\mathbf{\Theta})}{p(\mathbf{X})}
\end{equation}

Then, the Maximum A Posteriori (MAP) estimate can be found from
\begin{equation}
\mathbf{\hat{\Theta}}_{MAP} \; : \; \frac{p(\mathbf{\Theta}|\mathbf{X})}{\partial \mathbf{\Theta}} = \frac{\partial p(\mathbf{\Theta}) p(\mathbf{X}|\mathbf{\Theta})}{\partial \mathbf{\Theta}} = 0
\end{equation}




\subsection{Regression Models}





\subsection{Markov Models}
As an example of the model based approaches for event prediction we review models that are based on Markov Models and Hidden Markov Models (HMM). A discrete time Markov chain (DTMC) is a set of states:
\begin{align*}
S = \{S_i\}, 1 \le i \le N
\end{align*}

Let's denote the state at the time $t$ by $q_t$. A Markov Chain has the following property
\begin{align*}
P(q_t = S_i | q_{t-1} = S_{i-1}, q_{t-2} = S_{i-2}, ..., q_0 = s_0) = P(q_t = S_i | q_{t-1} = S_{i-1})
\end{align*}

In other words, the probability distribution of the next state depends only on the current state of the system. These transition probabilities between the states are defined by a stochastic transition matrix $A = [a_{ij}]$. The vector $\pi = [\pi_i]$ defines the initial probability distribution for each state.

A Hidden Markov Model (HMM) differs from the previous model so that its states are not observable. Instead, there is a set of observation symbols
\begin{align*}
O = \{O_k\}, 1 \le k \le M,
\end{align*}

which are observed in the state $S_i$ according to a probability distribution $b_i(k)$. These distributions define an observation matrix $B = [b_i(k)]$ ($N \times M$) \cite{rabiner89}.






